import streamlit as st
import os
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv
import tempfile
import fitz  # PyMuPDF
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì„ íƒ ì‚¬í•­, ë¡œì»¬ í™˜ê²½ì—ì„œ .env íŒŒì¼ì„ ì‚¬ìš©í•˜ë ¤ë©´)
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ“š PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“š PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    # OpenAI API í‚¤ ì…ë ¥ ë°›ê¸°
    user_api_key = st.text_input("OpenAI API í‚¤", type="password")  # API í‚¤ ì…ë ¥ ë°›ê¸°

    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ API í‚¤ë¡œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    if user_api_key:
        os.environ["OPENAI_API_KEY"] = user_api_key

    st.markdown("---")
    st.markdown("### ğŸ” ëª¨ë¸ ì„¤ì •")
    # ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        "OpenAI ëª¨ë¸ ì„ íƒ",
        ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
        index=0
    )
    temperature = st.slider("Temperature", min_value=0.0, max_value=1.0, value=0.3, step=0.1)

    st.markdown("---")
    st.markdown("### ğŸ“Š ì²­í¬ ì„¤ì •")
    # ì²­í¬ í¬ê¸°, ì˜¤ë²„ë© ì„¤ì •
    chunk_size = st.slider("ì²­í¬ í¬ê¸°", min_value=500, max_value=2000, value=1000, step=100)
    chunk_overlap = st.slider("ì²­í¬ ì˜¤ë²„ë©", min_value=0, max_value=500, value=100, step=50)

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_pdf(pdf_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
        temp_file.write(pdf_file.getvalue())
        temp_file_path = temp_file.name

    doc = fitz.open(temp_file_path)
    text = ""
    for page in doc:
        text += page.get_text("text") + "\n"
    
    doc.close()
    
    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.unlink(temp_file_path)
    return text

# ë²¡í„° ì €ì¥ì†Œ ìƒì„± í•¨ìˆ˜
def create_vectorstore(text, embeddings):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", " ", ""]
    )
    documents = text_splitter.create_documents([text])
    return FAISS.from_documents(documents, embeddings), len(documents)

# PDF ì—…ë¡œë“œì™€ ì§ˆì˜ì‘ë‹µ íƒ­ ìƒì„±
tab1, tab2 = st.tabs(["ğŸ“¤ PDF ì—…ë¡œë“œ", "â“ ì§ˆì˜ì‘ë‹µ"])

with tab1:
    st.header("PDF íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type="pdf")

    if uploaded_file is not None:
        with st.spinner("PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = extract_text_from_pdf(uploaded_file)
            st.session_state.pdf_text = text

            # í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            st.subheader("PDF í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", text[:1000] + ("..." if len(text) > 1000 else ""), height=200)

            # ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë²„íŠ¼
            if st.button("ë²¡í„° ì €ì¥ì†Œ ìƒì„±"):
                if "OPENAI_API_KEY" not in os.environ:
                    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘..."):
                        try:
                            embeddings = OpenAIEmbeddings()

                            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                            vectorstore, num_chunks = create_vectorstore(text, embeddings)
                            st.session_state.vectorstore = vectorstore
                            st.session_state.document_chunks = num_chunks

                            st.success(f"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ! {num_chunks}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.info("ì´ì œ 'ì§ˆì˜ì‘ë‹µ' íƒ­ì—ì„œ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!")
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

with tab2:
    st.header("PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")

    if 'vectorstore' not in st.session_state:
        st.warning("ë¨¼ì € 'PDF ì—…ë¡œë“œ' íƒ­ì—ì„œ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        st.success(f"âœ… {st.session_state.get('document_chunks', 0)}ê°œì˜ ì²­í¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì§ˆë¬¸ ì…ë ¥
        query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?")

        if query:
            if "OPENAI_API_KEY" not in os.environ:
                st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        # LLM ë° ê²€ìƒ‰ ì²´ì¸ ì„¤ì •
                        llm = ChatOpenAI(model_name=model_name, temperature=temperature)
                        
                        # ê²€ìƒ‰ê¸° ì„¤ì •
                        retriever = st.session_state.vectorstore.as_retriever(
                            search_type="similarity", search_kwargs={"k": 3}
                        )

                        # QA ì²´ì¸ ìƒì„±
                        qa_chain = RetrievalQA.from_chain_type(
                            llm=llm,
                            chain_type="stuff",
                            retriever=retriever,
                            return_source_documents=True
                        )

                        # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
                        result = qa_chain({"query": query})

                        # ê²°ê³¼ í‘œì‹œ
                        st.subheader("ğŸ“ ë‹µë³€")
                        st.write(result["result"])

                        # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                        with st.expander("ğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ì²­í¬"):
                            for i, doc in enumerate(result["source_documents"]):
                                st.markdown(f"**ì²­í¬ {i+1}**")
                                st.text(doc.page_content)
                                st.markdown("---")

                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# í‘¸í„°
st.markdown("---")
st.caption("ë©‹ìŸì´ ì‚¬ìì²˜ëŸ¼")